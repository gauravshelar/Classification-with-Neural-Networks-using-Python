{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e914f79",
   "metadata": {},
   "source": [
    "# Classification with Neural Networks using Python..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8927b",
   "metadata": {},
   "source": [
    "In machine learning, classification means categorizing the known classes, For example, categorizing the most profitable and non-interested customers from a dataset for advertising a particular product. You must have trained a classification model with a machine learning algorithm before. Here is an example. But if you want to learn about training a classification model with neural networks, this article is for you. In this article, I will take you through the task of classification with neural networks using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551c270",
   "metadata": {},
   "source": [
    "Classification is the task of categorizing the known classes based on their features. In most classification problems, machine learning algorithms will do the job, but while classifying a large dataset of images, you will need to use a neural network. If you have never trained a neural network and want to learn how neural networks work, you can learn everything about a neural network from here.\n",
    "\n",
    "Now let’s come back to classification with neural networks. In this section, I will take you through the task of image classification with neural network using Python. Here, I will be using the famous MNIST fashion dataset, which contains 70,000 clothing fashion images. Here our task is to train an image classification model with neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98429057",
   "metadata": {},
   "source": [
    "##### I will start this task by importing the necessary Python libraries and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa20e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b74434",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = keras.datasets.fashion_mnist\n",
    "(x_train,y_train),(x_test, y_test) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0949d73",
   "metadata": {},
   "source": [
    "##### Before moving forward, let’s have a quick look at one of the samples of the images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5c8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = 9\n",
    "image = x_train[img]\n",
    "print('Image Label:',y_train[img])\n",
    "plt.figure(figsize =(6,8))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9b07b",
   "metadata": {},
   "source": [
    "##### Now let’s have a look at the shape of both the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0469f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fbfbe",
   "metadata": {},
   "source": [
    "#### Building a Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d1451",
   "metadata": {},
   "source": [
    "###### Now I will build a neural network architecture with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991c9e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation ='relu'),\n",
    "    keras.layers.Dense(100, activation ='relu'),\n",
    "    keras.layers.Dense(10,activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67dc1f",
   "metadata": {},
   "source": [
    "#### Before training our model, I will split the training data into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3add924",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid, x_train = x_train[:5000]/255.0, x_train[5000:]/255.0\n",
    "yvalid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc3c6a",
   "metadata": {},
   "source": [
    "### Training a Classification Model with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce111d8b",
   "metadata": {},
   "source": [
    "Now here’s how we can train a neural network for the task of image classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "663de8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 12s 5ms/step - loss: 0.7427 - accuracy: 0.7583 - val_loss: 0.5412 - val_accuracy: 0.8112\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4895 - accuracy: 0.8287 - val_loss: 0.4435 - val_accuracy: 0.8452\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4456 - accuracy: 0.8438 - val_loss: 0.4178 - val_accuracy: 0.8542\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4188 - accuracy: 0.8531 - val_loss: 0.3889 - val_accuracy: 0.8692\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3977 - accuracy: 0.8599 - val_loss: 0.3939 - val_accuracy: 0.8620\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3825 - accuracy: 0.8667 - val_loss: 0.3708 - val_accuracy: 0.8700\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3672 - accuracy: 0.8702 - val_loss: 0.3535 - val_accuracy: 0.8766\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3562 - accuracy: 0.8750 - val_loss: 0.3453 - val_accuracy: 0.8778\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3463 - accuracy: 0.8762 - val_loss: 0.3385 - val_accuracy: 0.8818\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3353 - accuracy: 0.8816 - val_loss: 0.3339 - val_accuracy: 0.8816\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3266 - accuracy: 0.8841 - val_loss: 0.3359 - val_accuracy: 0.8810\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3183 - accuracy: 0.8870 - val_loss: 0.3516 - val_accuracy: 0.8752\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3105 - accuracy: 0.8899 - val_loss: 0.3283 - val_accuracy: 0.8828\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3047 - accuracy: 0.8911 - val_loss: 0.3304 - val_accuracy: 0.8848\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2973 - accuracy: 0.8931 - val_loss: 0.3238 - val_accuracy: 0.8824\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2919 - accuracy: 0.8958 - val_loss: 0.3298 - val_accuracy: 0.8826\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2851 - accuracy: 0.8986 - val_loss: 0.3137 - val_accuracy: 0.8886\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2802 - accuracy: 0.9003 - val_loss: 0.3096 - val_accuracy: 0.8876\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2746 - accuracy: 0.9013 - val_loss: 0.3273 - val_accuracy: 0.8834\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2692 - accuracy: 0.9036 - val_loss: 0.3061 - val_accuracy: 0.8906\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2640 - accuracy: 0.9052 - val_loss: 0.3139 - val_accuracy: 0.8892\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2596 - accuracy: 0.9066 - val_loss: 0.2995 - val_accuracy: 0.8956\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2544 - accuracy: 0.9093 - val_loss: 0.3301 - val_accuracy: 0.8822\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2504 - accuracy: 0.9096 - val_loss: 0.3242 - val_accuracy: 0.8820\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2464 - accuracy: 0.9115 - val_loss: 0.3091 - val_accuracy: 0.8862\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2417 - accuracy: 0.9139 - val_loss: 0.3092 - val_accuracy: 0.8868\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2374 - accuracy: 0.9157 - val_loss: 0.2985 - val_accuracy: 0.8912\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2343 - accuracy: 0.9162 - val_loss: 0.2927 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2306 - accuracy: 0.9168 - val_loss: 0.2914 - val_accuracy: 0.8950\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2267 - accuracy: 0.9197 - val_loss: 0.3011 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=30, \n",
    "                    validation_data=(xvalid, yvalid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f09d92",
   "metadata": {},
   "source": [
    "Now let’s have a look at the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea0889b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "new = x_test[:5]\n",
    "predictions = model.predict(new)\n",
    "print(predication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a607c",
   "metadata": {},
   "source": [
    "Here is how we can look at the predicted classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47f46677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "classes = np.argmax(predictions,axis =1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679b2a8",
   "metadata": {},
   "source": [
    "##### So this is how you can train a classification model with neural networks using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4845af3",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Classification is the task of categorizing the known classes based on their features. In most classification problems, machine learning algorithms will do the job, but while classifying a large dataset of images, you will need to use a neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
